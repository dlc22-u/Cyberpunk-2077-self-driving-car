{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 5.089885365962982\n",
      "Epoch 2/100, Loss: 1.4241427159309388\n",
      "Epoch 3/100, Loss: 0.4524289619922638\n",
      "Epoch 4/100, Loss: 0.40766318440437316\n",
      "Epoch 5/100, Loss: 0.40406485795974734\n",
      "Epoch 6/100, Loss: 0.38881996750831604\n",
      "Epoch 7/100, Loss: 0.3880790030956268\n",
      "Epoch 8/100, Loss: 0.3888913929462433\n",
      "Epoch 9/100, Loss: 0.38452597975730896\n",
      "Epoch 10/100, Loss: 0.3918797528743744\n",
      "Epoch 11/100, Loss: 0.3861772406101227\n",
      "Epoch 12/100, Loss: 0.3800950503349304\n",
      "Epoch 13/100, Loss: 0.37518787026405337\n",
      "Epoch 14/100, Loss: 0.3679965341091156\n",
      "Epoch 15/100, Loss: 0.3692064851522446\n",
      "Epoch 16/100, Loss: 0.36501635909080504\n",
      "Epoch 17/100, Loss: 0.35977696418762206\n",
      "Epoch 18/100, Loss: 0.36474592447280885\n",
      "Epoch 19/100, Loss: 0.36670536279678345\n",
      "Epoch 20/100, Loss: 0.3592632019519806\n",
      "Epoch 21/100, Loss: 0.35158018112182615\n",
      "Epoch 22/100, Loss: 0.362984277009964\n",
      "Epoch 23/100, Loss: 0.3590904605388641\n",
      "Epoch 24/100, Loss: 0.3621082258224487\n",
      "Epoch 25/100, Loss: 0.34561349630355837\n",
      "Epoch 26/100, Loss: 0.3461213493347168\n",
      "Epoch 27/100, Loss: 0.3575468814373016\n",
      "Epoch 28/100, Loss: 0.35080999970436094\n",
      "Epoch 29/100, Loss: 0.34172642827033994\n",
      "Epoch 30/100, Loss: 0.3365799498558044\n",
      "Epoch 31/100, Loss: 0.3270842385292053\n",
      "Epoch 32/100, Loss: 0.3361885941028595\n",
      "Epoch 33/100, Loss: 0.31931227684020996\n",
      "Epoch 34/100, Loss: 0.3265200042724609\n",
      "Epoch 35/100, Loss: 0.3218553137779236\n",
      "Epoch 36/100, Loss: 0.3215333157777786\n",
      "Epoch 37/100, Loss: 0.32517326295375826\n",
      "Epoch 38/100, Loss: 0.3151672691106796\n",
      "Epoch 39/100, Loss: 0.3092430579662323\n",
      "Epoch 40/100, Loss: 0.3103376305103302\n",
      "Epoch 41/100, Loss: 0.30372582614421845\n",
      "Epoch 42/100, Loss: 0.2996703696250915\n",
      "Epoch 43/100, Loss: 0.28685506582260134\n",
      "Epoch 44/100, Loss: 0.3034093588590622\n",
      "Epoch 45/100, Loss: 0.30326793968677523\n",
      "Epoch 46/100, Loss: 0.3018405604362488\n",
      "Epoch 47/100, Loss: 0.3023108559846878\n",
      "Epoch 48/100, Loss: 0.2847271138429642\n",
      "Epoch 49/100, Loss: 0.2814120781421661\n",
      "Epoch 50/100, Loss: 0.2678421187400818\n",
      "Epoch 51/100, Loss: 0.26955878257751464\n",
      "Epoch 52/100, Loss: 0.26122368752956393\n",
      "Epoch 53/100, Loss: 0.26742767930030825\n",
      "Epoch 54/100, Loss: 0.26086682319641114\n",
      "Epoch 55/100, Loss: 0.2639167535305023\n",
      "Epoch 56/100, Loss: 0.25451421678066255\n",
      "Epoch 57/100, Loss: 0.24222733974456787\n",
      "Epoch 58/100, Loss: 0.25572365283966064\n",
      "Epoch 59/100, Loss: 0.2555100095272064\n",
      "Epoch 60/100, Loss: 0.24205625891685487\n",
      "Epoch 61/100, Loss: 0.2258279502391815\n",
      "Epoch 62/100, Loss: 0.21377373814582826\n",
      "Epoch 63/100, Loss: 0.23668681740760802\n",
      "Epoch 64/100, Loss: 0.21404708683490753\n",
      "Epoch 65/100, Loss: 0.2049701678752899\n",
      "Epoch 66/100, Loss: 0.20665979206562043\n",
      "Epoch 67/100, Loss: 0.20473637104034423\n",
      "Epoch 68/100, Loss: 0.200602245926857\n",
      "Epoch 69/100, Loss: 0.1951245105266571\n",
      "Epoch 70/100, Loss: 0.18239857017993927\n",
      "Epoch 71/100, Loss: 0.17611398011446\n",
      "Epoch 72/100, Loss: 0.1674875181913376\n",
      "Epoch 73/100, Loss: 0.16471911013126372\n",
      "Epoch 74/100, Loss: 0.160001237988472\n",
      "Epoch 75/100, Loss: 0.16662068128585816\n",
      "Epoch 76/100, Loss: 0.15966896802186967\n",
      "Epoch 77/100, Loss: 0.13619956821203233\n",
      "Epoch 78/100, Loss: 0.1371593278646469\n",
      "Epoch 79/100, Loss: 0.14790616899728776\n",
      "Epoch 80/100, Loss: 0.12352387592196465\n",
      "Epoch 81/100, Loss: 0.12744687765836715\n",
      "Epoch 82/100, Loss: 0.1348719409108162\n",
      "Epoch 83/100, Loss: 0.15314981907606126\n",
      "Epoch 84/100, Loss: 0.12853407204151154\n",
      "Epoch 85/100, Loss: 0.1187540590763092\n",
      "Epoch 86/100, Loss: 0.11782153621315956\n",
      "Epoch 87/100, Loss: 0.11713910102844238\n",
      "Epoch 88/100, Loss: 0.11076594203710556\n",
      "Epoch 89/100, Loss: 0.10149010375142098\n",
      "Epoch 90/100, Loss: 0.11393840491771698\n",
      "Epoch 91/100, Loss: 0.10035088688135146\n",
      "Epoch 92/100, Loss: 0.09135376319289207\n",
      "Epoch 93/100, Loss: 0.08896243646740913\n",
      "Epoch 94/100, Loss: 0.08797855988144875\n",
      "Epoch 95/100, Loss: 0.08403468273580074\n",
      "Epoch 96/100, Loss: 0.08941623657941818\n",
      "Epoch 97/100, Loss: 0.0729265047609806\n",
      "Epoch 98/100, Loss: 0.086497006341815\n",
      "Epoch 99/100, Loss: 0.0678227224200964\n",
      "Epoch 100/100, Loss: 0.06700562879443168\n",
      "Finished Training\n",
      "Model saved to modified_cnn_model_with_speed.pth\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from keras.models import load_model\n",
    "from pynput.keyboard import Key, Controller, Listener\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "# 특정 키들\n",
    "valid_keys = ['w', 'a', 's', 'd']\n",
    "special_labels = ['no_keys_pressed']\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class KeypressDataset(Dataset):\n",
    "    def __init__(self, base_folders, transform=None, w_ratio=0.3, nokey_ratio = 0.5):\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.speeds = []\n",
    "\n",
    "        for base_folder in base_folders:\n",
    "            # 속도 값을 저장할 경로\n",
    "            speed_file_path = os.path.join(base_folder, 'text', 'speed.txt')\n",
    "\n",
    "            # 속도 값 읽기\n",
    "            with open(speed_file_path, 'r') as f:\n",
    "                speed_values = [float(line.strip()) for line in f]\n",
    "\n",
    "            # 유효한 폴더 이름만 필터링\n",
    "            label_folders = [f for f in os.listdir(base_folder) if os.path.isdir(os.path.join(base_folder, f)) and self.is_valid_label(f)]\n",
    "\n",
    "            # 각 폴더 내의 모든 이미지 경로를 수집\n",
    "            all_image_paths = []\n",
    "            for label_folder in label_folders:\n",
    "                folder_path = os.path.join(base_folder, label_folder)\n",
    "                image_paths = glob.glob(os.path.join(folder_path, '*.png'))\n",
    "                for img_path in image_paths:\n",
    "                    all_image_paths.append((img_path, label_folder))\n",
    "\n",
    "            # 파일 이름을 기준으로 정렬\n",
    "            all_image_paths.sort(key=lambda x: int(os.path.basename(x[0]).split('.')[0]))\n",
    "\n",
    "            # 정렬된 이미지 경로와 라벨, 속도 값을 각각 저장\n",
    "            for i, (img_path, label_folder) in enumerate(all_image_paths):\n",
    "                label_array = self.label_to_array(label_folder)\n",
    "                # 'w' 데이터의 비율을 조정\n",
    "                if label_array == [1, 0, 0, 0]:\n",
    "                    if random.random() > w_ratio:\n",
    "                        continue\n",
    "                # if label_array == [1, 1, 0, 0]:\n",
    "                #     if random.random() > w_ratio:\n",
    "                #         continue\n",
    "                # if label_array == [1, 0, 0, 1]:\n",
    "                #     if random.random() > w_ratio:\n",
    "                #         continue\n",
    "                if label_array == [0, 0, 0, 0]:\n",
    "                    if random.random() > nokey_ratio:\n",
    "                        continue\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(label_array)\n",
    "                self.speeds.append(speed_values[i])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        speed = self.speeds[idx]\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float), torch.tensor(speed, dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "    def is_valid_label(self, label):\n",
    "        if label in special_labels:\n",
    "            return True\n",
    "        for char in label.split('_'):\n",
    "            if char not in valid_keys:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def label_to_array(self, label):\n",
    "        if label == 'no_keys_pressed':\n",
    "            return [0, 0, 0, 0]\n",
    "        array = [0, 0, 0, 0]\n",
    "        for char in label.split('_'):\n",
    "            if char in valid_keys:\n",
    "                index = valid_keys.index(char)\n",
    "                array[index] = 1\n",
    "        return array\n",
    "\n",
    "# 데이터 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # 이미지 크기 조정\n",
    "    transforms.ToTensor(),  # 텐서로 변환\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 정규화\n",
    "])\n",
    "\n",
    "# CNN 모델 정의 (속도 값 추가)\n",
    "class ModifiedCNNModelWithSpeed(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModifiedCNNModelWithSpeed, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(256 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512 + 1, 4)  # 속도 값을 추가한 노드 수 (512 + 1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()  # 시그모이드 활성화 함수\n",
    "\n",
    "    def forward(self, x, speed):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(self.relu(self.bn4(self.conv4(x))))\n",
    "        x = x.view(-1, 256 * 8 * 8)\n",
    "        x = self.relu(self.fc1(x))\n",
    "\n",
    "        # 속도 값을 추가하여 입력으로 사용\n",
    "        x = torch.cat((x, speed), dim=1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.fc2(x))  # 시그모이드 활성화\n",
    "        return x\n",
    "\n",
    "# 학습 루프 정의\n",
    "num_epochs = 100\n",
    "\n",
    "def train_model(base_folders):\n",
    "    # 데이터셋 및 데이터로더 생성\n",
    "    dataset = KeypressDataset(base_folders=base_folders, transform=transform, w_ratio=0.5, nokey_ratio = 0.5)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)  # num_workers=2로 설정\n",
    "\n",
    "    # 모델, 손실 함수, 최적화 알고리즘 설정\n",
    "    model = ModifiedCNNModelWithSpeed()\n",
    "    criterion = nn.BCELoss()  # 이진 크로스 엔트로피 손실 함수\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels, speeds in dataloader:\n",
    "            # 모델 예측 초기화\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 순전파 + 역전파 + 최적화\n",
    "            outputs = model(images, speeds)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 손실 누적\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(dataloader)}')\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    # 모델 저장\n",
    "    torch.save(model.state_dict(), 'modified_cnn_model_with_speed.pth')\n",
    "    print('Model saved to modified_cnn_model_with_speed.pth')\n",
    "\n",
    "def predict_image(image_path, speed, model, transform):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "    speed = torch.tensor([[speed]], dtype=torch.float)  # 속도 값을 텐서로 변환\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image, speed)\n",
    "        output = output.squeeze().numpy()\n",
    "\n",
    "    return output\n",
    "\n",
    "# 모델 로드 및 추론\n",
    "def load_model_and_predict(image_path, speed):\n",
    "    # 모델 인스턴스 생성 및 가중치 로드\n",
    "    model = ModifiedCNNModelWithSpeed()\n",
    "    model.load_state_dict(torch.load('modified_cnn_model_with_speed.pth'))\n",
    "    model.eval()\n",
    "\n",
    "    # 이미지 예측\n",
    "    prediction = predict_image(image_path, speed, model, transform)\n",
    "    print(f'Prediction for {image_path} with speed {speed}: {prediction}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # mp.set_start_method('spawn')\n",
    "    # 현재 디렉토리의 모든 폴더를 base_folders로 설정\n",
    "\n",
    "    current_directory = os.getcwd()\n",
    "    base_folders = [os.path.join(current_directory, name) for name in os.listdir(current_directory) if os.path.isdir(os.path.join(current_directory, name))]\n",
    "\n",
    "    # 학습 모델\n",
    "    train_model(base_folders)\n",
    "\n",
    "    # 추론 예시\n",
    "    # example_image_path = 'path_to_your_image.png'\n",
    "    # example_speed = 0.7\n",
    "    # load_model_and_predict(example_image_path, example_speed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for screenshots_20240607-024658/a/19.png with speed 80: [3.8110595e-02 8.3816338e-01 5.7020073e-04 5.0863409e-06]\n",
      "Prediction for screenshots_20240607-024658/a_w/33.png with speed 88: [8.2777435e-01 9.2151177e-01 8.6279528e-05 4.5925929e-04]\n",
      "Prediction for screenshots_20240607-024658/d_w/12.png with speed 94: [4.0236190e-01 1.8015543e-03 3.2642987e-04 4.8683730e-01]\n",
      "Prediction for screenshots_20240607-024058/w/15.png with speed 86: [9.8386776e-01 6.6202033e-06 1.0456417e-10 1.8290447e-02]\n",
      "Prediction for screenshots_20240607-024058/s/77.png with speed 35: [8.4734135e-13 5.4380320e-07 9.9733633e-01 3.4091322e-06]\n",
      "Prediction for screenshots_20240607-024822/d/50.png with speed 83: [2.8228235e-01 4.0299376e-04 1.1603635e-05 6.8229479e-01]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "example_image_path = 'screenshots_20240607-024658/a/19.png'\n",
    "example_speed = 80\n",
    "load_model_and_predict(example_image_path, example_speed)\n",
    "example_image_path = 'screenshots_20240607-024658/a_w/33.png'\n",
    "example_speed = 88\n",
    "load_model_and_predict(example_image_path, example_speed)\n",
    "example_image_path = 'screenshots_20240607-024658/d_w/12.png'\n",
    "example_speed = 94\n",
    "load_model_and_predict(example_image_path, example_speed)\n",
    "example_image_path = 'screenshots_20240607-024058/w/15.png'\n",
    "example_speed = 86\n",
    "load_model_and_predict(example_image_path, example_speed)\n",
    "example_image_path = 'screenshots_20240607-024058/s/77.png'\n",
    "example_speed = 35\n",
    "load_model_and_predict(example_image_path, example_speed)\n",
    "example_image_path = 'screenshots_20240607-024822/d/50.png'\n",
    "example_speed = 83\n",
    "load_model_and_predict(example_image_path, example_speed)\n",
    "example_image_path = 'screenshots_20240607-024822/no_keys_pressed/6.png'\n",
    "example_speed = 47\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageGrab, Image\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import cv2\n",
    "from pynput.keyboard import Key, Controller, Listener\n",
    "\n",
    "# 특정 키들\n",
    "valid_keys = ['w', 'a', 's', 'd']\n",
    "\n",
    "# 데이터 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # 이미지 크기 조정\n",
    "    transforms.ToTensor(),  # 텐서로 변환\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 정규화\n",
    "])\n",
    "\n",
    "\n",
    "# CNN 모델 정의 (속도 값 추가)\n",
    "class ModifiedCNNModelWithSpeed(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModifiedCNNModelWithSpeed, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(256 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512 + 1, 4)  # 속도 값을 추가한 노드 수 (512 + 1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()  # 시그모이드 활성화 함수\n",
    "\n",
    "    def forward(self, x, speed):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(self.relu(self.bn4(self.conv4(x))))\n",
    "        x = x.view(-1, 256 * 8 * 8)\n",
    "        x = self.relu(self.fc1(x))\n",
    "\n",
    "        # 속도 값을 추가하여 입력으로 사용\n",
    "        x = torch.cat((x, speed), dim=1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.fc2(x))  # 시그모이드 활성화\n",
    "        return x\n",
    "\n",
    "# 모델 로드\n",
    "model = ModifiedCNNModelWithSpeed()\n",
    "model.load_state_dict(torch.load('modified_cnn_model_with_speed.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 속도 예측 모델 로드\n",
    "speed_model = load_model('speed_rec.h5')\n",
    "\n",
    "# 키보드 컨트롤러\n",
    "keyboard = Controller()\n",
    "\n",
    "# 화면 및 속도 영역 정의\n",
    "screen_region = (320, 170, 1650, 1080)\n",
    "speed_region = (145, 905, 202, 940)\n",
    "\n",
    "# ESC 키 종료 플래그\n",
    "exit_flag = False\n",
    "\n",
    "def on_press(key):\n",
    "    global exit_flag\n",
    "    if key == Key.esc:\n",
    "        exit_flag = True\n",
    "        return False\n",
    "\n",
    "def get_speed(speed_image):\n",
    "    speed_image = cv2.cvtColor(speed_image, cv2.COLOR_BGR2GRAY)  # Grayscale로 변환\n",
    "    speed_image = speed_image.astype('float32') / 255  # 정규화\n",
    "    speed_image = np.expand_dims(speed_image, axis=0)\n",
    "    speed_image = np.expand_dims(speed_image, axis=-1)  # 채널 차원 추가\n",
    "    # speed = speed_model.predict(speed_image)[0][0]\n",
    "    # return speed\n",
    "    prediction = speed_model.predict(speed_image)\n",
    "    predicted_label = np.argmax(prediction, axis=1)[0]\n",
    "\n",
    "    return predicted_label\n",
    "\n",
    "with Listener(on_press=on_press) as listener:\n",
    "    while not exit_flag:\n",
    "        # 화면 캡처\n",
    "        screen = ImageGrab.grab(bbox=screen_region)\n",
    "        screen = np.array(screen)\n",
    "        screen = cv2.cvtColor(screen, cv2.COLOR_BGR2RGB)\n",
    "        screen_image = Image.fromarray(screen)\n",
    "        \n",
    "        # 속도 캡처\n",
    "        speed_screen = ImageGrab.grab(bbox=speed_region)\n",
    "        speed_screen = np.array(speed_screen)\n",
    "        speed_screen = cv2.cvtColor(speed_screen, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 속도 예측\n",
    "        speed = get_speed(speed_screen)\n",
    "        speed_tensor = torch.tensor([[speed]], dtype=torch.float)\n",
    "\n",
    "        # 이미지 변환\n",
    "        screen_image = transform(screen_image)\n",
    "        screen_image = screen_image.unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "        # 모델 예측\n",
    "        with torch.no_grad():\n",
    "            output = model(screen_image, speed_tensor)\n",
    "            output = output.squeeze().numpy()\n",
    "\n",
    "        # 예측 확률에 따른 키 입력\n",
    "        pressed_keys = []\n",
    "        for i, prob in enumerate(output):\n",
    "            if prob >= 0.5:\n",
    "                key = valid_keys[i]\n",
    "                pressed_keys.append(key)\n",
    "                keyboard.press(key)\n",
    "            else:\n",
    "                key = valid_keys[i]\n",
    "                keyboard.release(key)\n",
    "\n",
    "        # 콘솔에 속도 값과 입력된 키 표시\n",
    "        print(f'Speed: {speed}, Keys: {\" \".join(pressed_keys)}')\n",
    "        print(f'[ {output[0]:.4f} ] [ {output[1]:.4f} ] [ {output[2]:.4f} ] [ {output[3]:.4f} ]')\n",
    "\n",
    "        # ESC 키로 프로그램 종료\n",
    "        if exit_flag:\n",
    "            break\n",
    "\n",
    "    listener.join()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
