{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 5.426036196947098\n",
      "Epoch 2/100, Loss: 1.2774269104003906\n",
      "Epoch 3/100, Loss: 0.6213228866457939\n",
      "Epoch 4/100, Loss: 0.459464368224144\n",
      "Epoch 5/100, Loss: 0.4292375653982162\n",
      "Epoch 6/100, Loss: 0.4215790256857872\n",
      "Epoch 7/100, Loss: 0.41119040697813036\n",
      "Epoch 8/100, Loss: 0.4082477703690529\n",
      "Epoch 9/100, Loss: 0.41265960335731505\n",
      "Epoch 10/100, Loss: 0.3925954535603523\n",
      "Epoch 11/100, Loss: 0.3911722630262375\n",
      "Epoch 12/100, Loss: 0.3917572647333145\n",
      "Epoch 13/100, Loss: 0.37806845009326934\n",
      "Epoch 14/100, Loss: 0.366902656853199\n",
      "Epoch 15/100, Loss: 0.3634263128042221\n",
      "Epoch 16/100, Loss: 0.34569570422172546\n",
      "Epoch 17/100, Loss: 0.3394492655992508\n",
      "Epoch 18/100, Loss: 0.34503253996372224\n",
      "Epoch 19/100, Loss: 0.3301431715488434\n",
      "Epoch 20/100, Loss: 0.33617582321166994\n",
      "Epoch 21/100, Loss: 0.31042805761098863\n",
      "Epoch 22/100, Loss: 0.3053630590438843\n",
      "Epoch 23/100, Loss: 0.2968664221465588\n",
      "Epoch 24/100, Loss: 0.29202721118927\n",
      "Epoch 25/100, Loss: 0.2867175221443176\n",
      "Epoch 26/100, Loss: 0.2703568287193775\n",
      "Epoch 27/100, Loss: 0.2618921399116516\n",
      "Epoch 28/100, Loss: 0.25438438057899476\n",
      "Epoch 29/100, Loss: 0.25468303114175794\n",
      "Epoch 30/100, Loss: 0.2334882065653801\n",
      "Epoch 31/100, Loss: 0.24519325643777848\n",
      "Epoch 32/100, Loss: 0.22014518603682517\n",
      "Epoch 33/100, Loss: 0.21461869925260543\n",
      "Epoch 34/100, Loss: 0.2282726712524891\n",
      "Epoch 35/100, Loss: 0.20954159945249556\n",
      "Epoch 36/100, Loss: 0.2015280772000551\n",
      "Epoch 37/100, Loss: 0.1946346417069435\n",
      "Epoch 38/100, Loss: 0.17482864558696748\n",
      "Epoch 39/100, Loss: 0.16676767580211163\n",
      "Epoch 40/100, Loss: 0.1751179076731205\n",
      "Epoch 41/100, Loss: 0.15924702137708663\n",
      "Epoch 42/100, Loss: 0.15021046251058578\n",
      "Epoch 43/100, Loss: 0.13019102215766906\n",
      "Epoch 44/100, Loss: 0.14366838335990906\n",
      "Epoch 45/100, Loss: 0.1174734454602003\n",
      "Epoch 46/100, Loss: 0.11202205587178468\n",
      "Epoch 47/100, Loss: 0.11394820623099804\n",
      "Epoch 48/100, Loss: 0.10414418391883373\n",
      "Epoch 49/100, Loss: 0.12500253655016422\n",
      "Epoch 50/100, Loss: 0.09310650704428554\n",
      "Epoch 51/100, Loss: 0.08770348895341158\n",
      "Epoch 52/100, Loss: 0.0835900254547596\n",
      "Epoch 53/100, Loss: 0.08448923700489104\n",
      "Epoch 54/100, Loss: 0.06104079708456993\n",
      "Epoch 55/100, Loss: 0.07517947033047676\n",
      "Epoch 56/100, Loss: 0.07060841042548419\n",
      "Epoch 57/100, Loss: 0.07178484974429011\n",
      "Epoch 58/100, Loss: 0.09673365708440543\n",
      "Epoch 59/100, Loss: 0.07918612081557512\n",
      "Epoch 60/100, Loss: 0.059410516545176505\n",
      "Epoch 61/100, Loss: 0.06490319464355707\n",
      "Epoch 62/100, Loss: 0.06820007339119911\n",
      "Epoch 63/100, Loss: 0.055203319946303966\n",
      "Epoch 64/100, Loss: 0.042617870634421705\n",
      "Epoch 65/100, Loss: 0.04754743245430291\n",
      "Epoch 66/100, Loss: 0.03412043247371912\n",
      "Epoch 67/100, Loss: 0.03754454941954464\n",
      "Epoch 68/100, Loss: 0.04578654034994543\n",
      "Epoch 69/100, Loss: 0.039897143468260766\n",
      "Epoch 70/100, Loss: 0.03808655480388552\n",
      "Epoch 71/100, Loss: 0.033692474593408406\n",
      "Epoch 72/100, Loss: 0.026086838450282812\n",
      "Epoch 73/100, Loss: 0.04217780800536275\n",
      "Epoch 74/100, Loss: 0.03936766469851136\n",
      "Epoch 75/100, Loss: 0.0335344020742923\n",
      "Epoch 76/100, Loss: 0.02304002511082217\n",
      "Epoch 77/100, Loss: 0.023435765993781388\n",
      "Epoch 78/100, Loss: 0.02511276805307716\n",
      "Epoch 79/100, Loss: 0.03028016269672662\n",
      "Epoch 80/100, Loss: 0.02514760330086574\n",
      "Epoch 81/100, Loss: 0.023788998369127512\n",
      "Epoch 82/100, Loss: 0.02351157837547362\n",
      "Epoch 83/100, Loss: 0.030443646130152047\n",
      "Epoch 84/100, Loss: 0.040168952336534856\n",
      "Epoch 85/100, Loss: 0.04942606631666422\n",
      "Epoch 86/100, Loss: 0.044544604257680476\n",
      "Epoch 87/100, Loss: 0.02707720424514264\n",
      "Epoch 88/100, Loss: 0.0340532906819135\n",
      "Epoch 89/100, Loss: 0.03387232376262546\n",
      "Epoch 90/100, Loss: 0.022892001329455524\n",
      "Epoch 91/100, Loss: 0.02145852263784036\n",
      "Epoch 92/100, Loss: 0.017365549673559143\n",
      "Epoch 93/100, Loss: 0.032346127193886784\n",
      "Epoch 94/100, Loss: 0.02138908742927015\n",
      "Epoch 95/100, Loss: 0.03437806111760437\n",
      "Epoch 96/100, Loss: 0.022593633690848946\n",
      "Epoch 97/100, Loss: 0.01426208550838055\n",
      "Epoch 98/100, Loss: 0.013173000203096308\n",
      "Epoch 99/100, Loss: 0.019800113316159697\n",
      "Epoch 100/100, Loss: 0.028108081410755402\n",
      "Finished Training\n",
      "Model saved to modified_cnn_model_with_speed.pth\n"
     ]
    }
   ],
   "source": [
    "#canny training\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# 특정 키들\n",
    "valid_keys = ['w', 'a', 's', 'd']\n",
    "special_labels = ['no_keys_pressed']\n",
    "\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class KeypressDataset(Dataset):\n",
    "    def __init__(self, base_folders, transform=None, w_ratio=0.1, nokey_ratio = 0.3):\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.speeds = []\n",
    "\n",
    "        for base_folder in base_folders:\n",
    "            # 속도 값을 저장할 경로\n",
    "            speed_file_path = os.path.join(base_folder, 'text', 'speed.txt')\n",
    "\n",
    "            # 속도 값 읽기\n",
    "            with open(speed_file_path, 'r') as f:\n",
    "                speed_values = [float(line.strip()) for line in f]\n",
    "\n",
    "            # 유효한 폴더 이름만 필터링\n",
    "            label_folders = [f for f in os.listdir(base_folder) if os.path.isdir(os.path.join(base_folder, f)) and self.is_valid_label(f)]\n",
    "\n",
    "            # 각 폴더 내의 모든 이미지 경로를 수집\n",
    "            all_image_paths = []\n",
    "            for label_folder in label_folders:\n",
    "                folder_path = os.path.join(base_folder, label_folder)\n",
    "                image_paths = glob.glob(os.path.join(folder_path, '*.png'))\n",
    "                for img_path in image_paths:\n",
    "                    all_image_paths.append((img_path, label_folder))\n",
    "\n",
    "            # 파일 이름을 기준으로 정렬\n",
    "            all_image_paths.sort(key=lambda x: int(os.path.basename(x[0]).split('.')[0]))\n",
    "\n",
    "            # 정렬된 이미지 경로와 라벨, 속도 값을 각각 저장\n",
    "            for i, (img_path, label_folder) in enumerate(all_image_paths):\n",
    "                label_array = self.label_to_array(label_folder)\n",
    "                # 'w' 데이터의 비율을 조정\n",
    "                if label_array == [1, 0, 0, 0]:\n",
    "                    if random.random() > w_ratio:\n",
    "                        continue\n",
    "                # if label_array == [1, 1, 0, 0]:\n",
    "                #     if random.random() > w_ratio:\n",
    "                #         continue\n",
    "                # if label_array == [1, 0, 0, 1]:\n",
    "                #     if random.random() > w_ratio:\n",
    "                #         continue\n",
    "                if label_array == [0, 0, 0, 0]:\n",
    "                    if random.random() > nokey_ratio:\n",
    "                        continue\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(label_array)\n",
    "                self.speeds.append(speed_values[i])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        # Canny Edge Detection 적용\n",
    "        image = np.array(image)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray, 50, 150)\n",
    "        image = Image.fromarray(edges).convert('L')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        speed = self.speeds[idx]\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float), torch.tensor(speed, dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "\n",
    "    def is_valid_label(self, label):\n",
    "        if label in special_labels:\n",
    "            return True\n",
    "        for char in label.split('_'):\n",
    "            if char not in valid_keys:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def label_to_array(self, label):\n",
    "        if label == 'no_keys_pressed':\n",
    "            return [0, 0, 0, 0]\n",
    "        array = [0, 0, 0, 0]\n",
    "        for char in label.split('_'):\n",
    "            if char in valid_keys:\n",
    "                index = valid_keys.index(char)\n",
    "                array[index] = 1\n",
    "        return array\n",
    "\n",
    "\n",
    "# 데이터 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # 이미지 크기 조정\n",
    "    transforms.ToTensor(),  # 텐서로 변환\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # 정규화\n",
    "])\n",
    "\n",
    "# CNN 모델 정의 (속도 값 추가)\n",
    "class ModifiedCNNModelWithSpeed(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModifiedCNNModelWithSpeed, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(256 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512 + 1, 4)  # 속도 값을 추가한 노드 수 (512 + 1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()  # 시그모이드 활성화 함수\n",
    "\n",
    "    def forward(self, x, speed):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(self.relu(self.bn4(self.conv4(x))))\n",
    "        x = x.view(-1, 256 * 8 * 8)\n",
    "        x = self.relu(self.fc1(x))\n",
    "\n",
    "        # 속도 값을 추가하여 입력으로 사용\n",
    "        x = torch.cat((x, speed), dim=1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.fc2(x))  # 시그모이드 활성화\n",
    "        return x\n",
    "\n",
    "# 학습 루프 정의\n",
    "num_epochs = 100\n",
    "\n",
    "def train_model(base_folders):\n",
    "    # 데이터셋 및 데이터로더 생성\n",
    "    dataset = KeypressDataset(base_folders=base_folders, transform=transform, w_ratio=0.5)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)  # num_workers=2로 설정\n",
    "\n",
    "    # 모델, 손실 함수, 최적화 알고리즘 설정\n",
    "    model = ModifiedCNNModelWithSpeed()\n",
    "    criterion = nn.BCELoss()  # 이진 크로스 엔트로피 손실 함수\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels, speeds in dataloader:\n",
    "            # 모델 예측 초기화\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 순전파 + 역전파 + 최적화\n",
    "            outputs = model(images, speeds)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 손실 누적\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(dataloader)}')\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    # 모델 저장\n",
    "    torch.save(model.state_dict(), 'canny_cnn_model_with_speed.pth')\n",
    "    print('Model saved to modified_cnn_model_with_speed.pth')\n",
    "\n",
    "def predict_image(image_path, speed, model, transform):\n",
    "    image = Image.open(image_path).convert('RGB')  # 흑백 이미지로 변환\n",
    "    image = np.array(image)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    image = Image.fromarray(edges).convert('L')\n",
    "    \n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "    speed = torch.tensor([[speed]], dtype=torch.float)  # 속도 값을 텐서로 변환\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image, speed)\n",
    "        output = output.squeeze().numpy()\n",
    "\n",
    "    return output\n",
    "\n",
    "# 모델 로드 및 추론\n",
    "def load_model_and_predict(image_path, speed):\n",
    "    # 모델 인스턴스 생성 및 가중치 로드\n",
    "    model = ModifiedCNNModelWithSpeed()\n",
    "    model.load_state_dict(torch.load('canny_cnn_model_with_speed.pth'))\n",
    "    model.eval()\n",
    "\n",
    "    # 이미지 예측\n",
    "    prediction = predict_image(image_path, speed, model, transform)\n",
    "    print(f'Prediction for {image_path} with speed {speed}: {prediction}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 현재 디렉토리의 모든 폴더를 base_folders로 설정\n",
    "    current_directory = os.getcwd()\n",
    "    base_folders = [os.path.join(current_directory, name) for name in os.listdir(current_directory) if os.path.isdir(os.path.join(current_directory, name))]\n",
    "\n",
    "    # 학습 모델\n",
    "    train_model(base_folders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for screenshots_20240607-024658/a/19.png with speed 80: [9.9588267e-09 9.9997604e-01 1.8373146e-07 9.4943038e-12]\n",
      "Prediction for screenshots_20240607-024658/a_w/33.png with speed 88: [9.7978961e-01 8.6037475e-01 1.7116236e-09 1.0352658e-08]\n",
      "Prediction for screenshots_20240607-024658/d_w/12.png with speed 94: [9.9998951e-01 1.9691676e-14 1.0033234e-13 9.9999988e-01]\n",
      "Prediction for screenshots_20240607-024058/w/15.png with speed 86: [5.1354098e-01 9.1393513e-06 2.6515499e-07 5.7524145e-01]\n",
      "Prediction for screenshots_20240607-024058/s/77.png with speed 35: [4.5626420e-16 1.2318348e-07 9.9990678e-01 2.5492294e-11]\n",
      "Prediction for screenshots_20240607-024822/d/50.png with speed 83: [1.9615683e-04 3.9473969e-05 2.2515645e-03 9.8425722e-01]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# test\n",
    "example_image_path = 'screenshots_20240607-024658/a/19.png'\n",
    "example_speed = 80\n",
    "load_model_and_predict(example_image_path, example_speed)\n",
    "example_image_path = 'screenshots_20240607-024658/a_w/33.png'\n",
    "example_speed = 88\n",
    "load_model_and_predict(example_image_path, example_speed)\n",
    "example_image_path = 'screenshots_20240607-024658/d_w/12.png'\n",
    "example_speed = 94\n",
    "load_model_and_predict(example_image_path, example_speed)\n",
    "example_image_path = 'screenshots_20240607-024058/w/15.png'\n",
    "example_speed = 86\n",
    "load_model_and_predict(example_image_path, example_speed)\n",
    "example_image_path = 'screenshots_20240607-024058/s/77.png'\n",
    "example_speed = 35\n",
    "load_model_and_predict(example_image_path, example_speed)\n",
    "example_image_path = 'screenshots_20240607-024822/d/50.png'\n",
    "example_speed = 83\n",
    "load_model_and_predict(example_image_path, example_speed)\n",
    "example_image_path = 'screenshots_20240607-024822/no_keys_pressed/6.png'\n",
    "example_speed = 47\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Speed: 94, Keys: w\n",
      "[ 1.0000 ] [ 0.0000 ] [ 0.0000 ] [ 0.0000 ]\n"
     ]
    }
   ],
   "source": [
    "#eval\n",
    "from keras.models import load_model\n",
    "from pynput.keyboard import Key, Controller, Listener\n",
    "from PIL import ImageGrab, Image\n",
    "# 속도 예측 모델 로드\n",
    "speed_model = load_model('speed_rec.h5')\n",
    "\n",
    "# 키보드 컨트롤러\n",
    "keyboard = Controller()\n",
    "\n",
    "# 화면 및 속도 영역 정의\n",
    "screen_region = (320, 170, 1650, 1080)\n",
    "speed_region = (145, 905, 202, 940)\n",
    "\n",
    "# ESC 키 종료 플래그\n",
    "exit_flag = False\n",
    "\n",
    "def on_press(key):\n",
    "    global exit_flag\n",
    "    if key == Key.esc:\n",
    "        exit_flag = True\n",
    "        return False\n",
    "\n",
    "def get_speed(speed_image):\n",
    "    speed_image = cv2.cvtColor(speed_image, cv2.COLOR_BGR2GRAY)  # Grayscale로 변환\n",
    "    speed_image = speed_image.astype('float32') / 255  # 정규화\n",
    "    speed_image = np.expand_dims(speed_image, axis=0)\n",
    "    speed_image = np.expand_dims(speed_image, axis=-1)  # 채널 차원 추가\n",
    "    # speed = speed_model.predict(speed_image)[0][0]\n",
    "    # return speed\n",
    "    prediction = speed_model.predict(speed_image)\n",
    "    predicted_label = np.argmax(prediction, axis=1)[0]\n",
    "\n",
    "    return predicted_label\n",
    "\n",
    "with Listener(on_press=on_press) as listener:\n",
    "    while not exit_flag:\n",
    "        # 화면 캡처\n",
    "        screen = ImageGrab.grab(bbox=screen_region)\n",
    "        screen = np.array(screen)\n",
    "        screen = cv2.cvtColor(screen, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(screen, 50, 150)\n",
    "        image = Image.fromarray(edges).convert('L')\n",
    "        screen_image = Image.fromarray(screen)\n",
    "        \n",
    "        # 속도 캡처\n",
    "        speed_screen = ImageGrab.grab(bbox=speed_region)\n",
    "        speed_screen = np.array(speed_screen)\n",
    "        speed_screen = cv2.cvtColor(speed_screen, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 속도 예측\n",
    "        speed = get_speed(speed_screen)\n",
    "        speed_tensor = torch.tensor([[speed]], dtype=torch.float)\n",
    "\n",
    "        # 이미지 변환\n",
    "        screen_image = transform(screen_image)\n",
    "        screen_image = screen_image.unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "        # 모델 예측\n",
    "        # with torch.no_grad():\n",
    "        #     output = model(screen_image, speed_tensor)\n",
    "        #     output = output.squeeze().numpy()\n",
    "\n",
    "        model = ModifiedCNNModelWithSpeed()\n",
    "        model.load_state_dict(torch.load('canny_cnn_model_with_speed.pth'))\n",
    "        model.eval()\n",
    "    \n",
    "        # 이미지 예측\n",
    "        with torch.no_grad():\n",
    "            output = model(screen_image, speed_tensor)\n",
    "            output = output.squeeze().numpy()\n",
    "\n",
    "        # 예측 확률에 따른 키 입력\n",
    "        pressed_keys = []\n",
    "        for i, prob in enumerate(output):\n",
    "            if prob >= 0.7:\n",
    "                key = valid_keys[i]\n",
    "                pressed_keys.append(key)\n",
    "                keyboard.press(key)\n",
    "            else:\n",
    "                key = valid_keys[i]\n",
    "                keyboard.release(key)\n",
    "\n",
    "        # 콘솔에 속도 값과 입력된 키 표시\n",
    "        print(f'Speed: {speed}, Keys: {\" \".join(pressed_keys)}')\n",
    "        print(f'[ {output[0]:.4f} ] [ {output[1]:.4f} ] [ {output[2]:.4f} ] [ {output[3]:.4f} ]')\n",
    "\n",
    "        # ESC 키로 프로그램 종료\n",
    "        if exit_flag:\n",
    "            break\n",
    "\n",
    "    listener.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
